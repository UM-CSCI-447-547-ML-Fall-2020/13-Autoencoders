{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "A very interesting case emerges when we ask a neural network to reconstruct its input when we impose a bottleneck: a hidden layer with substantially fewer nodes than the input.  This forces the neural network to come up with a compressed representation of the data.  For example, we can imagine taking the MNIST dataset, and generating a neural network with one input layer, three hidden layers, and one output layer.  Then, we'll set the number of nodes in that middle hidden layer to two. This will force the model to come up with a distillation of the 784-dimensional dataset into a 2-D representation, and will also force the training of neural network weights to re-constitute that encoding back into the full 784D representation.  Note that we've seen this kind of thing before in the form of PCA.  However, that relied on a linear transformation, namely the orthogonal rotation of the coordinate system.  A neural network is much more powerful because it can perform non-linear transformations.  Let's see what this can do for us.\n",
    "\n",
    "First we'll import Torch along with the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X/=255.\n",
    "y = y.astype(int)\n",
    "X,X_test,y,y_test = train_test_split(X,y,test_size=10000)\n",
    "\n",
    "# Extract number of data points, and the height and width of the images for later reshaping\n",
    "m = X.shape[0]\n",
    "n = X.shape[1]\n",
    "\n",
    "h = 28\n",
    "w = 28\n",
    "\n",
    "N = 10\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y = torch.from_numpy(y)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "X = X.to(torch.float32)\n",
    "X_test = X_test.to(torch.float32)\n",
    "y = y.to(torch.long)\n",
    "y_test = y_test.to(torch.long)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X = X.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y = y.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "training_data = TensorDataset(X,y)\n",
    "test_data = TensorDataset(X_test,y_test)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "batch_size = 256\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can specify some parameters of the network architecture.  For the so-called latent dimension (the bottleneck), we'll use only two nodes, meaning that any representation of a handwritten digit will be a vector in $\\mathbb{R}^2$.  For the hidden layers between, we'll use 128 nodes.\n",
    "\n",
    "$$\\Sigma = \\frac{1}{m} \\sum_{i=1}^m (X - \\bar{X})^T (X - \\bar{X})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "intermediate_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll specify our network architecture.  Because we'll want to re-use the weights of various layers in several models (namely functions from the input to the latent variables, from latent variables to outputs, and directly from input to output), I've structured this in such a way that we instantiate all the layers, then arrange them into the needed networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,n,latent_dim,intermediate_dim):\n",
    "        \"\"\"\n",
    "        This method is where you'll want to instantiate parameters.\n",
    "        we do this by creating two linear transformation functions, l1 and l2, which \n",
    "        have encoded in it both the weight matrices W_1 and W_2, and the bias vectors\n",
    "        \"\"\"\n",
    "        super(Encoder,self).__init__()\n",
    "        self.l1 = nn.Linear(n,intermediate_dim) # Transform from input to hidden layer\n",
    "        self.l2 = nn.Linear(intermediate_dim,latent_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        This method runs the feedforward neural network.  It takes a tensor of size m x 784,\n",
    "        applies a linear transformation, applies a sigmoidal activation, applies the second linear transform \n",
    "        and outputs the logits.\n",
    "        \"\"\"\n",
    "        a1 = self.l1(x)\n",
    "        z1 = torch.relu(a1)   \n",
    "        \n",
    "        a2 = self.l2(z1)  \n",
    "        return a2\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,n,latent_dim,intermediate_dim):\n",
    "        \"\"\"\n",
    "        This method is where you'll want to instantiate parameters.\n",
    "        we do this by creating two linear transformation functions, l1 and l2, which \n",
    "        have encoded in it both the weight matrices W_1 and W_2, and the bias vectors\n",
    "        \"\"\"\n",
    "        super(Decoder,self).__init__()\n",
    "        self.l1 = nn.Linear(latent_dim,intermediate_dim) # Transform from input to hidden layer\n",
    "        self.l2 = nn.Linear(intermediate_dim,n)\n",
    "        self.drop = nn.Dropout(p=0.8)\n",
    "    \n",
    "    def forward(self,z):\n",
    "        \"\"\"\n",
    "        This method runs the feedforward neural network.  It takes a tensor of size m x 784,\n",
    "        applies a linear transformation, applies a sigmoidal activation, applies the second linear transform \n",
    "        and outputs the logits.\n",
    "        \"\"\"\n",
    "        a1d = self.drop(z)\n",
    "        a1 = self.l1(a1d)\n",
    "        z1 = torch.relu(a1)   \n",
    "        \n",
    "        a2 = self.l2(z1)  \n",
    "        return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(n,latent_dim,intermediate_dim)\n",
    "encoder.to(device)\n",
    "\n",
    "decoder = Decoder(n,latent_dim,intermediate_dim)\n",
    "decoder.to(device)\n",
    "\n",
    "for layer in [encoder.l1,encoder.l2,decoder.l1,decoder.l2]:\n",
    "    layer.weight.data[:] = 0\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([e for e in encoder.parameters()]+[p for p in decoder.parameters()],lr=1e-3)\n",
    "\n",
    "gamma = 1.0e-2\n",
    "epochs = 50\n",
    "# Loop over the data\n",
    "for epoch in range(epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    # Loop over each subset of data\n",
    "    l = 0\n",
    "    n_batches = 0\n",
    "    for d,_ in train_loader:\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make a prediction based on the model\n",
    "        latent = encoder(d)\n",
    "        reconstruction = decoder(latent)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(reconstruction,d)\n",
    "        for layer in [encoder.l1,encoder.l2,decoder.l1,decoder.l2]:\n",
    "            loss += gamma*torch.mean(layer.weight**2)\n",
    "        \n",
    "        # Use backpropagation to compute the derivative of the loss with respect to the parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Use the derivative information to update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        l += loss.item()\n",
    "        n_batches += 1\n",
    "    print(l/n_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a minute to train, but once its done, we can look at the filters that we produce, just like we did with PCA (and with classifying MLPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder weights (Good features to extract)\n",
    "fig,axs = plt.subplots(nrows=1,ncols=5,figsize=(10,10))\n",
    "for i,ax in enumerate(axs):    \n",
    "    i = np.random.randint(intermediate_dim)\n",
    "    ax.imshow([e for e in encoder.parameters()][0][i,:].detach().cpu().numpy().reshape((28,28)))#,vmin=-0.3,vmax=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at how effective our autoencoder is: how well do we map back to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = decoder(encoder(X_test))\n",
    "index = 1\n",
    "fig,axs = plt.subplots(ncols=2)\n",
    "#index = np.random.randint(len(reconstruction))\n",
    "axs[0].imshow(reconstruction[index].reshape(28,28).detach().cpu().numpy(),vmin=0,vmax=1)\n",
    "axs[1].imshow(X_test[index].reshape(28,28).cpu().numpy(),vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does just OK.  But we are trying to distill all the variability in the MNIST dataset down into two numbers.  Let's look at those two numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_intermediate = encoder(X_test).detach().cpu().numpy()\n",
    "plt.scatter(z_intermediate[:,0],z_intermediate[:,1],c=y_test.detach().cpu().numpy())\n",
    "plt.colorbar()\n",
    "plt.xlabel('z_0')\n",
    "plt.ylabel('z_1')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dots are colored by digit.  There are clear distinctions between groups, but still quite a bit of overlap.  Nonetheless, we could make a pretty good classifier out of this (in fact this is what we're doing with an MLP).  \n",
    "\n",
    "We can also pick values of our latent variables, and generate a new digit using it, which is pretty neat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.from_numpy(np.array([0.,-4])).to(torch.float32).to(device)\n",
    "x_pred = decoder(z).reshape((28,28)).detach().cpu().numpy()\n",
    "plt.imshow(x_pred)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it's easy to get off the map.  If we wanted to randomly generate handwritten digits by sampling $z$, we'd have a hard time, because the distribution of z values doesn't follow anything specific.  This problem becomes especially acute in high latent-dimension (if the plot were 16D); there would be a very large separation between each of the classes, thus although sevens and ones should be \"close\" to each other, in high latent space, they tend not to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "intermediate_dim = 256\n",
    "\n",
    "encoder = Encoder(n,latent_dim,intermediate_dim)\n",
    "encoder.to(device)\n",
    "\n",
    "decoder = Decoder(n,latent_dim,intermediate_dim)\n",
    "decoder.to(device)\n",
    "\n",
    "#for layer in [encoder.l1,encoder.l2,decoder.l1,decoder.l2]:\n",
    "#    layer.weight.data[:] = 0\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([e for e in encoder.parameters()]+[p for p in decoder.parameters()],lr=1e-3)\n",
    "\n",
    "gamma = 1.0e-4\n",
    "epochs = 50\n",
    "# Loop over the data\n",
    "for epoch in range(epochs):\n",
    "    #model.train()\n",
    "    # Loop over each subset of data\n",
    "    l = 0\n",
    "    n_batches = 0\n",
    "    for d,_ in train_loader:\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make a prediction based on the model\n",
    "        latent = encoder(d)\n",
    "        reconstruction = decoder(latent)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(reconstruction,d)\n",
    "        for layer in [encoder.l1,encoder.l2,decoder.l1,decoder.l2]:\n",
    "            loss += gamma*torch.mean(layer.weight**2)\n",
    "        \n",
    "        # Use backpropagation to compute the derivative of the loss with respect to the parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Use the derivative information to update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        l += loss.item()\n",
    "        n_batches += 1\n",
    "    print(l/n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "z_intermediate = encoder(X_test).detach().cpu().numpy()\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(20,20)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = ax.scatter(z_intermediate[:,0],z_intermediate[:,1],z_intermediate[:,2],c=y_test.detach().cpu().numpy(),alpha=0.8)\n",
    "fig.colorbar(p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(ncols=2)\n",
    "index = np.random.randint(len(reconstruction))\n",
    "axs[0].imshow(reconstruction[index].reshape(28,28).detach().cpu().numpy(),vmin=0,vmax=1)\n",
    "axs[1].imshow(d[index].reshape(28,28).cpu().numpy(),vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising autoencoder\n",
    "\n",
    "The utility of this may not yet seem clear: we've developed a more expressive version of PCA.  However we can do some things that are more creative in this framework.  For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.cuda.FloatTensor(10, 10).uniform_() > 0.8\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "intermediate_dim = 256\n",
    "\n",
    "encoder = Encoder(n,latent_dim,intermediate_dim)\n",
    "encoder.to(device)\n",
    "\n",
    "decoder = Decoder(n,latent_dim,intermediate_dim)\n",
    "decoder.to(device)\n",
    "\n",
    "#for layer in [encoder.l1,encoder.l2,decoder.l1,decoder.l2]:\n",
    "#    layer.weight.data[:] = 0\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([e for e in encoder.parameters()]+[p for p in decoder.parameters()],lr=1e-3)\n",
    "\n",
    "gamma = 1.0e-4\n",
    "epochs = 50\n",
    "# Loop over the data\n",
    "for epoch in range(epochs):\n",
    "    #model.train()\n",
    "    # Loop over each subset of data\n",
    "    l = 0\n",
    "    n_batches = 0\n",
    "    for d,_ in train_loader:\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        std = 0.2\n",
    "        mask = torch.cuda.FloatTensor(*d.size()).uniform_() > rate\n",
    "        d_noisy = d*mask\n",
    "        \n",
    "        # Make a prediction based on the model\n",
    "        latent = encoder(d_noisy)\n",
    "        reconstruction = decoder(latent)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(reconstruction,d)\n",
    "        for layer in [encoder.l1,encoder.l2,decoder.l1,decoder.l2]:\n",
    "            loss += gamma*torch.mean(layer.weight**2)\n",
    "        \n",
    "        # Use backpropagation to compute the derivative of the loss with respect to the parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Use the derivative information to update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        l += loss.item()\n",
    "        n_batches += 1\n",
    "    print(l/n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.cuda.FloatTensor(*X_test.size()).uniform_() > rate\n",
    "X_test_noisy = X_test*mask\n",
    "reconstruction = decoder(encoder(X_test_noisy))\n",
    "\n",
    "fig,axs = plt.subplots(ncols=3,figsize=(10,10))\n",
    "index = np.random.randint(len(reconstruction))\n",
    "axs[0].imshow(reconstruction[index].reshape(28,28).detach().cpu().numpy(),vmin=0,vmax=1)\n",
    "axs[1].imshow(X_test_noisy[index].reshape(28,28).cpu().numpy(),vmin=0,vmax=1)\n",
    "axs[2].imshow(X_test[index].reshape(28,28).cpu().numpy(),vmin=0,vmax=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
